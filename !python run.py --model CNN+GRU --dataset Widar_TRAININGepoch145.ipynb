{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuo-liangliang/DeepLearning-check2023-2024/blob/FEDRT-LSTM_TSET-use-zhangmeng-2024.04.24/!python%20run.py%20--model%20CNN%2BGRU%20--dataset%20Widar_TRAININGepoch145.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS3ZliHYxQ_h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtumZaUZfG-P"
      },
      "outputs": [],
      "source": [
        "# 复制\n",
        "!cp -r /content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/DriverBVP[-1,1]bvplength20-分辨率15-手势4-BK /content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/DriverBVP[-1,1]bvplength20-分辨率15-手势4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPSiuMqfey3u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# 用户编号\n",
        "user_number = 'user14'\n",
        "# 指定目录路径\n",
        "directory = f'/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/DriverBVP[-1,1]bvplength20-分辨率15-手势4/{user_number}/'\n",
        "# 获取目录下所有文件\n",
        "files = os.listdir(directory)\n",
        "# 筛选出符合条件的文件名\n",
        "files_to_keep = []\n",
        "for file in files:\n",
        "    if file.startswith(f'{user_number}-') and file.endswith('.mat'):\n",
        "        parts = file.split('-')\n",
        "        a = int(parts[1])\n",
        "        b = int(parts[2])\n",
        "        #if b in [1, 2]:\n",
        "        if b in [1, 4]:\n",
        "            files_to_keep.append(file)\n",
        "# 删除不符合条件的文件\n",
        "for file in files:\n",
        "    if file not in files_to_keep:\n",
        "        os.remove(os.path.join(directory, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvsavS42Y8QW"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/NTU-Fi_HAR.zip\" -d \"/content/drive/MyDrive/check_yjf_2024.04.10/WiFi-CSI-Sensing-Benchmark-main/NTU-Fi_HAR/\"\n",
        "# 解压Zip文件到指定路径\n",
        "################################################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amX2d-r66deM"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV7neAy05cTe"
      },
      "outputs": [],
      "source": [
        "################################################################################################################################\n",
        "##############验证程序############验证程序###########验证程序##############验证程序########验证程序###########验证程序###########\n",
        "################################################################################################################################\n",
        "!pip install einops\n",
        "# !pip install torch==1.12.0 torchvision==0.13.0\n",
        "import torch\n",
        "import torchvision\n",
        "#!pip install torch torchvision torchaudio\n",
        "print(\"PyTorch 版本:\", torch.__version__)\n",
        "print(\"TorchVision 版本:\", torchvision.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMHKhhQO5jgI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng\"\n",
        "os.chdir(path)\n",
        "print(os.getcwd())\n",
        "# 更改运行目录，定位当前运行地址"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcrUiRWM2gKB"
      },
      "outputs": [],
      "source": [
        "# FEDRT-LSTM\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import os,sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as scio\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.keras.backend.set_session\n",
        "import keras\n",
        "from keras.layers import Input, GRU, LSTM, Dense, Flatten, Dropout, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, TimeDistributed\n",
        "from keras.models import Model, load_model\n",
        "import keras.backend as K\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization\n",
        "num_transformer_layers = 1  # 设置Transformer层数\n",
        "\n",
        "# Parameters\n",
        "use_existing_model = False  # 创建一个模型（False）默认创建一个新模型\n",
        "# use_existing_model = True    # 模型权重修改点 使用已经存在的模型（True）\n",
        "# data_dir = '/content/drive/MyDrive/Colab_Notebooks/528BVP-acnt2/528[-1,1]长度20-分辨率15_acnt2_剔14_改6为4/'   #修改数据集文件夹\n",
        "data_dir_training = '/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/528[-1,1]长度20-分辨率15_acnt2_剔14_改6为4/'\n",
        "data_dir_testing = '/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/DriverBVP[-1,1]bvplength20-分辨率15-手势4/'  # 修改为另外环境下的数据路径\n",
        "\n",
        "#fraction_for_test = 0.1 # 修改测试集占比 原先是0.1-->0.2\n",
        "#ALL_MOTION = [1,2,3,4,5,6]\n",
        "ALL_MOTION = [2,3,4,5]  # 这部分还可以改？\n",
        "N_MOTION = len(ALL_MOTION)\n",
        "T_MAX = 0\n",
        "n_epochs = 200 #200       #原始是30 #修改点1 取在528上最好的一组超参\n",
        "f_dropout_ratio = 0.5\n",
        "n_gru_hidden_units = 32\n",
        "n_batch_size = 32     #原始是32-->16\n",
        "f_learning_rate = 0.001  #原始是0.001-->0.002\n",
        "\n",
        "def normalize_data(data_1):\n",
        "    data_1_max = np.concatenate((data_1.max(axis=0),data_1.max(axis=1)),axis=0).max(axis=0)\n",
        "    data_1_min = np.concatenate((data_1.min(axis=0),data_1.min(axis=1)),axis=0).min(axis=0)\n",
        "    if (len(np.where((data_1_max - data_1_min) == 0)[0]) > 0):\n",
        "        return data_1\n",
        "    data_1_max_rep = np.tile(data_1_max,(data_1.shape[0],data_1.shape[1],1))\n",
        "    data_1_min_rep = np.tile(data_1_min,(data_1.shape[0],data_1.shape[1],1))\n",
        "    data_1_norm = (data_1 - data_1_min_rep) / (data_1_max_rep - data_1_min_rep)\n",
        "    return  data_1_norm\n",
        "\n",
        "def zero_padding(data, T_MAX):\n",
        "    data_pad = []\n",
        "    for i in range(len(data)):\n",
        "        t = np.array(data[i]).shape[2]\n",
        "        data_pad.append(np.pad(data[i], ((0,0),(0,0),(T_MAX - t,0)), 'constant', constant_values = 0).tolist())\n",
        "    return np.array(data_pad)\n",
        "\n",
        "def onehot_encoding(label, num_class):\n",
        "    label = np.array(label).astype('int32')\n",
        "    label = np.squeeze(label)\n",
        "    # _label = np.eye(num_class)[label-1]     # from label to onehot\n",
        "    _label = np.eye(num_class)[label-2]   #修改点2\n",
        "    return _label\n",
        "\n",
        "def load_data(path_to_data, motion_sel):\n",
        "    global T_MAX\n",
        "    data = []\n",
        "    label = []\n",
        "    for data_root, data_dirs, data_files in os.walk(path_to_data):\n",
        "        for data_file_name in data_files:\n",
        "            file_path = os.path.join(data_root,data_file_name)\n",
        "            try:\n",
        "                data_1 = scio.loadmat(file_path)['velocity_spectrum_ro']\n",
        "                label_1 = int(data_file_name.split('-')[1])\n",
        "                #repetition = int(data_file_name.split('-')[4])\n",
        "                repetition = int(data_file_name.split('-')[2])  #修改点3\n",
        "                # Select Motion\n",
        "                if (label_1 not in motion_sel):\n",
        "                    continue\n",
        "                data_normed_1 = normalize_data(data_1)\n",
        "                if T_MAX < np.array(data_1).shape[2]:\n",
        "                    T_MAX = np.array(data_1).shape[2]\n",
        "            except Exception:\n",
        "                continue\n",
        "            # Save List\n",
        "            data.append(data_normed_1.tolist())\n",
        "            label.append(label_1)\n",
        "                # Zero-padding\n",
        "    data = zero_padding(data, T_MAX)\n",
        "\n",
        "    # Swap axes\n",
        "    data = np.swapaxes(np.swapaxes(data, 1, 3), 2, 3)   # [N,20,20',T_MAX]=>[N,T_MAX,20,20']\n",
        "    data = np.expand_dims(data, axis=-1)    # [N,T_MAX,20,20]=>[N,T_MAX,20,20,1]\n",
        "\n",
        "    # Convert label to ndarray\n",
        "    label = np.array(label)\n",
        "\n",
        "    # data(ndarray): [N,T_MAX,20,20,1], label(ndarray): [N,N_MOTION]\n",
        "    return data, label\n",
        "\n",
        "# 构建符合输入形状为 (None, 20, 15, 15, 1) 和输出形状为 (None, 4) 的  模型：\n",
        "#加Transformer修改点3\n",
        "def transformer_layer(inputs, hidden_units, dropout_rate):\n",
        "    # Self-attention\n",
        "    attention_output = MultiHeadAttention(\n",
        "        num_heads=8, key_dim=hidden_units // 8\n",
        "    )(inputs, inputs)\n",
        "    attention_output = Dropout(dropout_rate)(attention_output)\n",
        "    attention_output = LayerNormalization()(attention_output + inputs)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ffn = Dense(hidden_units, activation=\"relu\")(attention_output)\n",
        "    ffn = Dense(hidden_units)(ffn)\n",
        "    ffn = Dropout(dropout_rate)(ffn)\n",
        "    ffn = LayerNormalization()(ffn)\n",
        "\n",
        "    return ffn\n",
        "\n",
        "#加Transformer修改点4\n",
        "def assemble_model(input_shape, n_class):\n",
        "    model_input = Input(shape=input_shape, dtype='float32', name='name_model_input')    # (@,T_MAX,20,20,1)\n",
        "\n",
        "    # Feature extraction part\n",
        "    x = TimeDistributed(Conv2D(16,kernel_size=(5,5),activation='relu',data_format='channels_last',\\\n",
        "        input_shape=input_shape))(model_input)   # (@,T_MAX,20,20,1)=>(@,T_MAX,16,16,16)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x)    # (@,T_MAX,16,16,16)=>(@,T_MAX,8,8,16)\n",
        "    x = TimeDistributed(Flatten())(x)   # (@,T_MAX,8,8,16)=>(@,T_MAX,8*8*16)\n",
        "    x = TimeDistributed(Dense(64,activation='relu'))(x) # (@,T_MAX,8*8*16)=>(@,T_MAX,64)\n",
        "    x = TimeDistributed(Dropout(f_dropout_ratio))(x)\n",
        "    x = TimeDistributed(Dense(64,activation='relu'))(x) # (@,T_MAX,64)=>(@,T_MAX,64)\n",
        "\n",
        "    # Add transformer layers\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = transformer_layer(x, hidden_units=64, dropout_rate=f_dropout_ratio)  # 修改点1\n",
        "    x = LSTM(n_gru_hidden_units,return_sequences=False)(x)  # (@,T_MAX,64)=>(@,128)\n",
        "    x = Dropout(f_dropout_ratio)(x)\n",
        "    model_output = Dense(n_class, activation='softmax', name='name_model_output')(x)  # (@,128)=>(@,n_class)\n",
        "\n",
        "    # Create the model\n",
        "    # Model compiling\n",
        "    model = Model(inputs=model_input, outputs=model_output)\n",
        "    model.compile(optimizer=keras.optimizers.RMSprop(lr=f_learning_rate),\n",
        "                    loss='mean_squared_error',  # 将损失函数改为均方误差\n",
        "                    metrics=['accuracy']\n",
        "                )\n",
        "    return model\n",
        "\n",
        "model_type = 'FEDRT-LSTM'\n",
        "\n",
        "# 创建结果文件夹\n",
        "result_folder = f'Result_528TRAIN10-zhangmengTEST2'\n",
        "os.makedirs(result_folder, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_ujmBdVPZzU"
      },
      "outputs": [],
      "source": [
        "# Let's BEGIN >>>>\n",
        "\n",
        "# 定义版本\n",
        "today_version = '2024.04.24_v0.1'\n",
        "\n",
        "import time\n",
        "start_time = time.time()  # 记录程序开始时间\n",
        "\n",
        "# 获取可见的 GPU 设备列表\n",
        "visible_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(visible_gpus) > 0:\n",
        "    # 如果有可见的 GPU 设备，设置 TensorFlow 在 GPU 上运行\n",
        "    tf.config.set_visible_devices(visible_gpus, 'GPU')\n",
        "    gpu_config = tf.config.experimental.set_memory_growth(visible_gpus[0], True)\n",
        "    sess = tf.compat.v1.Session(config=gpu_config)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "    print('GPU available')\n",
        "else:\n",
        "    # 如果没有可见的 GPU 设备，设置 TensorFlow 在 CPU 上运行\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "    sess = tf.compat.v1.Session()\n",
        "    print('No GPU available')\n",
        "\n",
        "# 加载训练集数据\n",
        "train_data, train_label = load_data(data_dir_training, ALL_MOTION)\n",
        "print('\\nLoaded dataset of ' + str(train_label.shape[0]) + ' samples, each sized ' + str(train_data[0,:,:].shape) + '\\n')\n",
        "\n",
        "# One-hot encoding for train data\n",
        "train_label = onehot_encoding(train_label, N_MOTION)\n",
        "\n",
        "##############################################################################\n",
        "# Load data\n",
        "# data, label = load_data(data_dir, ALL_MOTION)\n",
        "# print('\\nLoaded dataset of ' + str(label.shape[0]) + ' samples, each sized ' + str(data[0,:,:].shape) + '\\n')\n",
        "\n",
        "# Split train and test\n",
        "# [data_train, data_test, label_train, label_test] = train_test_split(data, label, test_size=fraction_for_test)\n",
        "# print('\\nTrain on ' + str(label_train.shape[0]) + ' samples\\n' +\\\n",
        "    # 'Test on ' + str(label_test.shape[0]) + ' samples\\n')\n",
        "\n",
        "# One-hot encoding for train data\n",
        "# label_train = onehot_encoding(label_train, N_MOTION)\n",
        "\n",
        "# Load or fabricate model\n",
        "if use_existing_model:\n",
        "    model = load_model('model_Transformer_MultiAttention_LSTM_mse_1层Transformer_epoch200_86.61%.h5')\n",
        "    # model = load_model('model_LSTM_91.07_best_trained.h5')\n",
        "    # model = load_model('model_MultiAttention_LSTM_1层Transformer_MSE_epoch200_BS32_lr0.001_86.61%.h5')\n",
        "    # model = load_model('MultiAttention_LSTM_mse_1层Transformer_epoch50_79.46%.h5')\n",
        "    model.summary()\n",
        "else:\n",
        "    model = assemble_model(input_shape=(T_MAX, 15, 15, 1), n_class=N_MOTION) #修改点4\n",
        "    model.summary()\n",
        "\n",
        "class AccuracyLossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.acc = []\n",
        "        self.loss = []\n",
        "        self.val_acc = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.acc.append(logs.get('accuracy'))\n",
        "        self.loss.append(logs.get('loss'))\n",
        "        self.val_acc.append(logs.get('val_accuracy'))\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "\n",
        "history = AccuracyLossHistory()\n",
        "\n",
        "# model.fit({'name_model_input': data_train},{'name_model_output': label_train},\n",
        "model.fit({'name_model_input': train_data},{'name_model_output': train_label},\n",
        "          batch_size=n_batch_size,\n",
        "          epochs=n_epochs,\n",
        "          verbose=1,\n",
        "          # validation_split=0.1,\n",
        "          shuffle=True, callbacks=[history])\n",
        "print('Saving trained model...')\n",
        "#model.save('model_widar3_trained.h5')\n",
        "model.save(f'{result_folder}/{today_version}_FEDRT-LSTM-train-model.h5')  # 改动\n",
        "\n",
        "# Testing...\n",
        "print('Testing...')\n",
        "\n",
        "# 加载测试集数据\n",
        "test_data, test_label = load_data(data_dir_testing, ALL_MOTION)\n",
        "print('\\nLoaded dataset of ' + str(test_label.shape[0]) + ' samples, each sized ' + str(test_data[0,:,:].shape) + '\\n')\n",
        "\n",
        "label_test_pred = model.predict(test_data)\n",
        "# label_test_pred = np.argmax(label_test_pred, axis = -1) + 2 #修改点5\n",
        "label_test_pred = np.argmax(label_test_pred, axis = -1) + 2 #修改点5 2024.04.24修改\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_label, label_test_pred)\n",
        "# print(cm)\n",
        "cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
        "# cm = np.around(cm, decimals=2) # 保留几位小数的意思\n",
        "cm = np.around(cm, decimals=4) # 保留几位小数的意思 2024.04.24修改\n",
        "\n",
        "# print(cm)\n",
        "# cm_display = ConfusionMatrixDisplay(cm, display_labels=range(1, N_MOTION+1)).plot()\n",
        "# cm_display = ConfusionMatrixDisplay(cm, display_labels=range(4, N_MOTION+3)).plot() #2345 lebel-2  4567 4=2+2  7=长度4+3\n",
        "# cm_display = ConfusionMatrixDisplay(cm, display_labels=range(2, N_MOTION+2)).plot() #2345 lebel-2  23456 4=2+2  6=长度4+2\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels=range(2, N_MOTION+2)).plot() #2024.04.24修改 #2345 lebel-2  23456 4=2+2  6=长度4+2\n",
        "plt.show()\n",
        "plt.savefig(f'{result_folder}/{today_version}_Confusion-Matrix.png') # 新增点1 保存混淆矩阵结果2023.09.11\n",
        "\n",
        "# ########################################################\n",
        "# 添加其他指标\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "\n",
        "# label_test_pred是模型的预测结果，test_label是真实的标签\n",
        "classification_result = classification_report(test_label, label_test_pred, digits=4)\n",
        "# 将digits设置为4，那么在生成的分类报告中，每个指标（如精确度、召回率、F1 分数等）将会显示四位小数\n",
        "print(classification_result)\n",
        "\n",
        "# 将分类报告保存到文本文件\n",
        "classification_file = os.path.join(result_folder, 'classification_report.txt')\n",
        "with open(classification_file, 'w') as f:\n",
        "    f.write(classification_result)\n",
        "\n",
        "###############################################################\n",
        "\n",
        "# Accuracy 新增百分号\n",
        "test_accuracy = np.sum(test_label == label_test_pred) / (test_label.shape[0])\n",
        "print(test_accuracy)\n",
        "test_accuracy_percentage = test_accuracy * 100\n",
        "test_accuracy_str = f\"{test_accuracy_percentage:.2f}%\"\n",
        "print(test_accuracy_str)\n",
        "\n",
        "df_accuracy = pd.DataFrame({'Test Accuracy': [test_accuracy]})\n",
        "df_accuracy.to_excel(f'{result_folder}/{test_accuracy_str}_{today_version}.xlsx', index=False) ## 新增点2 保存测试集平均准确率结果2023.09.11\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Epoch': range(1, n_epochs+1),\n",
        "    'Train Accuracy': history.acc,\n",
        "    'Train Loss': history.loss,\n",
        "    'Validation Accuracy': history.val_acc,\n",
        "    'Validation Loss': history.val_loss\n",
        "})\n",
        "\n",
        "# 保存准确率和损失数据到Excel表格中\n",
        "df.to_excel(f'{result_folder}/{today_version}_accuracy_loss.xlsx', index=False) #改动\n",
        "\n",
        "plt.plot(range(1, n_epochs+1), history.acc, label='Train Accuracy')\n",
        "plt.plot(range(1, n_epochs+1), history.loss, label='Train Loss')\n",
        "plt.plot(range(1, n_epochs+1), history.val_acc, label='Validation Accuracy')\n",
        "plt.plot(range(1, n_epochs+1), history.val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.savefig(f'{result_folder}/{today_version}_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 新增 修改文件名 并打印新的文件名\n",
        "# new_result_folder = result_folder + f'_{test_accuracy_str}'\n",
        "new_result_folder = result_folder + f'_{test_accuracy_str}_epoch{n_epochs}'# 2024.04.24修改\n",
        "# result_folder = f'result_{model_type}_BCE_epoch{n_epochs}_batchsize{n_batch_size}_lr{f_learning_rate}_test{fraction_for_test}'\n",
        "os.rename(result_folder, new_result_folder)\n",
        "result_folder = new_result_folder\n",
        "\n",
        "# print(\"新的结果文件夹名称为：\", result_folder)\n",
        "\n",
        "end_time = time.time()  # 记录程序结束时间\n",
        "duration = end_time - start_time  # 计算程序运行时间\n",
        "print(\"程序执行时间为：{:.2f}秒\".format(duration))\n",
        "\n",
        "with open(f'{result_folder}/{today_version}_runtime.txt', 'w') as f:\n",
        "    f.write(\"程序执行时间为：{:.2f}秒\".format(duration)) # 新增点3 保存程序执行时间结果2023.09.11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_INGrZ9z6iA",
        "outputId": "592134e4-fde2-4acf-92a5-8ce2da246252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "PyTorch 版本: 2.2.1+cu121\n",
            "TorchVision 版本: 0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "################################################################################################################################\n",
        "##############验证程序############验证程序###########验证程序##############验证程序########验证程序###########验证程序###########\n",
        "################################################################################################################################\n",
        "!pip install einops\n",
        "# !pip install torch==1.12.0 torchvision==0.13.0\n",
        "import torch\n",
        "import torchvision\n",
        "#!pip install torch torchvision torchaudio\n",
        "print(\"PyTorch 版本:\", torch.__version__)\n",
        "print(\"TorchVision 版本:\", torchvision.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko1SC43MTQWZ",
        "outputId": "4f579146-8e91-432d-83eb-15437714eb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/check_yjf_2024.04.10/WiFi-CSI-Sensing-Benchmark-main\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/check_yjf_2024.04.10/WiFi-CSI-Sensing-Benchmark-main\"\n",
        "os.chdir(path)\n",
        "print(os.getcwd())\n",
        "# 更改运行目录，定位当前运行地址"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-yTdJO6TNGq",
        "outputId": "db2fd0e4-7ad6-43fa-dc12-11ba6ff8cbbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using dataset: Widar\n",
            "using model: CNN+GRU\n",
            "Epoch:1, Accuracy:0.2051,Loss:2.9580\n",
            "Epoch:2, Accuracy:0.2081,Loss:2.9420\n",
            "Epoch:3, Accuracy:0.2114,Loss:2.9409\n",
            "Epoch:4, Accuracy:0.2153,Loss:2.9396\n",
            "Epoch:5, Accuracy:0.2420,Loss:2.9236\n",
            "Epoch:6, Accuracy:0.2534,Loss:2.9134\n",
            "Epoch:7, Accuracy:0.2549,Loss:2.9104\n",
            "Epoch:8, Accuracy:0.2568,Loss:2.9075\n",
            "Epoch:9, Accuracy:0.2650,Loss:2.8994\n",
            "Epoch:10, Accuracy:0.2721,Loss:2.8947\n",
            "Epoch:11, Accuracy:0.2740,Loss:2.8933\n",
            "Epoch:12, Accuracy:0.2803,Loss:2.8853\n",
            "Epoch:13, Accuracy:0.3037,Loss:2.8645\n",
            "Epoch:14, Accuracy:0.3228,Loss:2.8435\n",
            "Epoch:15, Accuracy:0.3280,Loss:2.8391\n",
            "Epoch:16, Accuracy:0.3423,Loss:2.8229\n",
            "Epoch:17, Accuracy:0.3384,Loss:2.8263\n",
            "Epoch:18, Accuracy:0.3607,Loss:2.8048\n",
            "Epoch:19, Accuracy:0.3865,Loss:2.7806\n",
            "Epoch:20, Accuracy:0.3973,Loss:2.7698\n",
            "Epoch:21, Accuracy:0.4024,Loss:2.7654\n",
            "Epoch:22, Accuracy:0.4099,Loss:2.7579\n",
            "Epoch:23, Accuracy:0.4150,Loss:2.7524\n",
            "Epoch:24, Accuracy:0.4303,Loss:2.7365\n",
            "Epoch:25, Accuracy:0.4332,Loss:2.7328\n",
            "Epoch:26, Accuracy:0.4388,Loss:2.7273\n",
            "Epoch:27, Accuracy:0.4555,Loss:2.7120\n",
            "Epoch:28, Accuracy:0.4645,Loss:2.7028\n",
            "Epoch:29, Accuracy:0.4564,Loss:2.7101\n",
            "Epoch:30, Accuracy:0.4697,Loss:2.6972\n",
            "Epoch:31, Accuracy:0.4860,Loss:2.6811\n",
            "Epoch:32, Accuracy:0.4993,Loss:2.6691\n",
            "Epoch:33, Accuracy:0.5037,Loss:2.6639\n",
            "Epoch:34, Accuracy:0.5276,Loss:2.6429\n",
            "Epoch:35, Accuracy:0.5336,Loss:2.6348\n",
            "Epoch:36, Accuracy:0.5502,Loss:2.6196\n",
            "Epoch:37, Accuracy:0.5791,Loss:2.5912\n",
            "Epoch:38, Accuracy:0.5911,Loss:2.5799\n",
            "Epoch:39, Accuracy:0.5914,Loss:2.5774\n",
            "Epoch:40, Accuracy:0.6046,Loss:2.5645\n",
            "Epoch:41, Accuracy:0.6071,Loss:2.5611\n",
            "Epoch:42, Accuracy:0.6229,Loss:2.5460\n",
            "Epoch:43, Accuracy:0.6276,Loss:2.5422\n",
            "Epoch:44, Accuracy:0.6449,Loss:2.5261\n",
            "Epoch:45, Accuracy:0.6504,Loss:2.5205\n",
            "Epoch:46, Accuracy:0.6689,Loss:2.5014\n",
            "Epoch:47, Accuracy:0.6724,Loss:2.4990\n",
            "Epoch:48, Accuracy:0.6832,Loss:2.4872\n",
            "Epoch:49, Accuracy:0.6956,Loss:2.4760\n",
            "Epoch:50, Accuracy:0.6989,Loss:2.4721\n",
            "Epoch:51, Accuracy:0.7105,Loss:2.4627\n",
            "Epoch:52, Accuracy:0.7051,Loss:2.4651\n",
            "Epoch:53, Accuracy:0.7227,Loss:2.4502\n",
            "Epoch:54, Accuracy:0.7172,Loss:2.4507\n",
            "Epoch:55, Accuracy:0.7292,Loss:2.4411\n",
            "Epoch:56, Accuracy:0.7247,Loss:2.4446\n",
            "Epoch:57, Accuracy:0.7327,Loss:2.4372\n",
            "Epoch:58, Accuracy:0.7423,Loss:2.4288\n",
            "Epoch:59, Accuracy:0.7343,Loss:2.4339\n",
            "Epoch:60, Accuracy:0.7410,Loss:2.4282\n",
            "Epoch:61, Accuracy:0.7369,Loss:2.4333\n",
            "Epoch:62, Accuracy:0.7480,Loss:2.4226\n",
            "Epoch:63, Accuracy:0.7480,Loss:2.4221\n",
            "Epoch:64, Accuracy:0.7496,Loss:2.4198\n",
            "Epoch:65, Accuracy:0.7456,Loss:2.4227\n",
            "Epoch:66, Accuracy:0.7618,Loss:2.4075\n",
            "Epoch:67, Accuracy:0.7641,Loss:2.4061\n",
            "Epoch:68, Accuracy:0.7605,Loss:2.4076\n",
            "Epoch:69, Accuracy:0.7670,Loss:2.4023\n",
            "Epoch:70, Accuracy:0.7737,Loss:2.3969\n",
            "Epoch:71, Accuracy:0.7700,Loss:2.3990\n",
            "Epoch:72, Accuracy:0.7758,Loss:2.3934\n",
            "Epoch:73, Accuracy:0.7633,Loss:2.4053\n",
            "Epoch:74, Accuracy:0.7659,Loss:2.4033\n",
            "Epoch:75, Accuracy:0.7731,Loss:2.3960\n",
            "Epoch:76, Accuracy:0.7760,Loss:2.3922\n",
            "Epoch:77, Accuracy:0.7693,Loss:2.3993\n",
            "Epoch:78, Accuracy:0.7816,Loss:2.3867\n",
            "Epoch:79, Accuracy:0.7870,Loss:2.3828\n",
            "Epoch:80, Accuracy:0.7755,Loss:2.3939\n",
            "Epoch:81, Accuracy:0.7781,Loss:2.3914\n",
            "Epoch:82, Accuracy:0.7874,Loss:2.3805\n",
            "Epoch:83, Accuracy:0.7830,Loss:2.3866\n",
            "Epoch:84, Accuracy:0.7838,Loss:2.3833\n",
            "Epoch:85, Accuracy:0.7857,Loss:2.3823\n",
            "Epoch:86, Accuracy:0.7929,Loss:2.3746\n",
            "Epoch:87, Accuracy:0.7826,Loss:2.3849\n",
            "Epoch:88, Accuracy:0.7849,Loss:2.3815\n",
            "Epoch:89, Accuracy:0.8013,Loss:2.3675\n",
            "Epoch:90, Accuracy:0.7874,Loss:2.3800\n",
            "Epoch:91, Accuracy:0.7888,Loss:2.3778\n",
            "Epoch:92, Accuracy:0.7991,Loss:2.3684\n",
            "Epoch:93, Accuracy:0.7943,Loss:2.3727\n",
            "Epoch:94, Accuracy:0.7905,Loss:2.3773\n",
            "Epoch:95, Accuracy:0.7895,Loss:2.3778\n",
            "Epoch:96, Accuracy:0.8020,Loss:2.3672\n",
            "Epoch:97, Accuracy:0.7996,Loss:2.3679\n",
            "Epoch:98, Accuracy:0.8107,Loss:2.3570\n",
            "Epoch:99, Accuracy:0.8126,Loss:2.3557\n",
            "Epoch:100, Accuracy:0.8241,Loss:2.3453\n",
            "Epoch:101, Accuracy:0.8283,Loss:2.3409\n",
            "Epoch:102, Accuracy:0.8288,Loss:2.3402\n",
            "Epoch:103, Accuracy:0.8266,Loss:2.3427\n",
            "Epoch:104, Accuracy:0.8247,Loss:2.3429\n",
            "Epoch:105, Accuracy:0.8330,Loss:2.3360\n",
            "Epoch:106, Accuracy:0.8380,Loss:2.3317\n",
            "Epoch:107, Accuracy:0.8409,Loss:2.3275\n",
            "Epoch:108, Accuracy:0.8387,Loss:2.3283\n",
            "Epoch:109, Accuracy:0.8456,Loss:2.3237\n",
            "Epoch:110, Accuracy:0.8403,Loss:2.3284\n",
            "Epoch:111, Accuracy:0.8410,Loss:2.3277\n",
            "Epoch:112, Accuracy:0.8433,Loss:2.3249\n",
            "Epoch:113, Accuracy:0.8454,Loss:2.3221\n",
            "Epoch:114, Accuracy:0.8358,Loss:2.3313\n",
            "Epoch:115, Accuracy:0.8448,Loss:2.3233\n",
            "Epoch:116, Accuracy:0.8441,Loss:2.3248\n",
            "Epoch:117, Accuracy:0.8434,Loss:2.3247\n",
            "Epoch:118, Accuracy:0.8488,Loss:2.3196\n",
            "Epoch:119, Accuracy:0.8356,Loss:2.3315\n",
            "Epoch:120, Accuracy:0.8424,Loss:2.3245\n",
            "Epoch:121, Accuracy:0.8604,Loss:2.3096\n",
            "Epoch:122, Accuracy:0.8514,Loss:2.3178\n",
            "Epoch:123, Accuracy:0.8536,Loss:2.3142\n",
            "Epoch:124, Accuracy:0.8549,Loss:2.3132\n",
            "Epoch:125, Accuracy:0.8586,Loss:2.3094\n",
            "Epoch:126, Accuracy:0.8588,Loss:2.3100\n",
            "Epoch:127, Accuracy:0.8582,Loss:2.3102\n",
            "Epoch:128, Accuracy:0.8541,Loss:2.3136\n",
            "Epoch:129, Accuracy:0.8580,Loss:2.3111\n",
            "Epoch:130, Accuracy:0.8590,Loss:2.3090\n",
            "Epoch:131, Accuracy:0.8636,Loss:2.3037\n",
            "Epoch:132, Accuracy:0.8619,Loss:2.3053\n",
            "Epoch:133, Accuracy:0.8478,Loss:2.3203\n",
            "Epoch:134, Accuracy:0.8514,Loss:2.3157\n",
            "Epoch:135, Accuracy:0.8619,Loss:2.3053\n",
            "Epoch:136, Accuracy:0.8565,Loss:2.3116\n",
            "Epoch:137, Accuracy:0.8622,Loss:2.3056\n",
            "Epoch:138, Accuracy:0.8563,Loss:2.3111\n",
            "Epoch:139, Accuracy:0.8571,Loss:2.3107\n",
            "Epoch:140, Accuracy:0.8597,Loss:2.3068\n",
            "Epoch:141, Accuracy:0.8645,Loss:2.3031\n",
            "Epoch:142, Accuracy:0.8613,Loss:2.3091\n",
            "Epoch:143, Accuracy:0.8601,Loss:2.3081\n",
            "Epoch:144, Accuracy:0.8653,Loss:2.3037\n",
            "Epoch:145, Accuracy:0.8641,Loss:2.3048\n"
          ]
        }
      ],
      "source": [
        "# epoch=200\n",
        "!python run.py --model CNN+GRU --dataset Widar\n",
        "# !python run.py --model GRU --dataset Widar\n",
        "# !python run.py --model LSTM --dataset Widar\n",
        "# !python run.py --model BiLSTM --dataset Widar\n",
        "# !python run.py --model RNN --dataset Widar\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Cz2jHsRGlIY8OLCF5RPplMv55tD0VoXd",
      "authorship_tag": "ABX9TyOS/zyxE1vyiYfhZLzs6pwU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}