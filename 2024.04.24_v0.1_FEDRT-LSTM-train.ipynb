{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1Cz2jHsRGlIY8OLCF5RPplMv55tD0VoXd",
      "authorship_tag": "ABX9TyM/2fUNxV/58B1ed3krKJAd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuo-liangliang/DeepLearning-check2023-2024/blob/FEDRT-LSTM_TSET-use-zhangmeng-2024.04.24/2024.04.24_v0.1_FEDRT-LSTM-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oS3ZliHYxQ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/NTU-Fi_HAR.zip\" -d \"/content/drive/MyDrive/check_yjf_2024.04.10/WiFi-CSI-Sensing-Benchmark-main/NTU-Fi_HAR/\"\n",
        "# 解压Zip文件到指定路径\n",
        "################################################################################################################################"
      ],
      "metadata": {
        "id": "WvsavS42Y8QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amX2d-r66deM",
        "outputId": "0dfc75eb-a62d-43fa-d2fd-00b2111f0a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################################################\n",
        "##############验证程序############验证程序###########验证程序##############验证程序########验证程序###########验证程序###########\n",
        "################################################################################################################################\n",
        "!pip install einops\n",
        "# !pip install torch==1.12.0 torchvision==0.13.0\n",
        "import torch\n",
        "import torchvision\n",
        "#!pip install torch torchvision torchaudio\n",
        "print(\"PyTorch 版本:\", torch.__version__)\n",
        "print(\"TorchVision 版本:\", torchvision.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV7neAy05cTe",
        "outputId": "552cf6de-6bae-4351-eeb1-a28bc7e135ca"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "PyTorch 版本: 2.2.1+cu121\n",
            "TorchVision 版本: 0.17.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng\"\n",
        "os.chdir(path)\n",
        "print(os.getcwd())\n",
        "# 更改运行目录，定位当前运行地址"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMHKhhQO5jgI",
        "outputId": "a4feb335-ce9b-4c8d-b89e-447715e1e277"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FEDRT-LSTM\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import os,sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as scio\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.keras.backend.set_session\n",
        "import keras\n",
        "from keras.layers import Input, GRU, LSTM, Dense, Flatten, Dropout, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, TimeDistributed\n",
        "from keras.models import Model, load_model\n",
        "import keras.backend as K\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization\n",
        "num_transformer_layers = 1  # 设置Transformer层数\n",
        "\n",
        "# Parameters\n",
        "use_existing_model = False  # 创建一个模型（False）默认创建一个新模型\n",
        "# use_existing_model = True    # 模型权重修改点 使用已经存在的模型（True）\n",
        "# data_dir = '/content/drive/MyDrive/Colab_Notebooks/528BVP-acnt2/528[-1,1]长度20-分辨率15_acnt2_剔14_改6为4/'   #修改数据集文件夹\n",
        "data_dir_training = '/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/528[-1,1]长度20-分辨率15_acnt2_剔14_改6为4/'\n",
        "data_dir_testing = '/content/drive/MyDrive/Result_FEDRT-LSTM_TSET-use-zhangmeng/DriverBVP[-1,1]bvplength20-分辨率15-手势4/'  # 修改为另外环境下的数据路径\n",
        "\n",
        "#fraction_for_test = 0.1 # 修改测试集占比 原先是0.1-->0.2\n",
        "#ALL_MOTION = [1,2,3,4,5,6]\n",
        "ALL_MOTION = [2,3,4,5]\n",
        "N_MOTION = len(ALL_MOTION)\n",
        "T_MAX = 0\n",
        "n_epochs = 200       #原始是30 #修改点1 取在528上最好的一组超参\n",
        "f_dropout_ratio = 0.5\n",
        "n_gru_hidden_units = 32\n",
        "n_batch_size = 32     #原始是32-->16\n",
        "f_learning_rate = 0.001  #原始是0.001-->0.002\n",
        "\n",
        "def normalize_data(data_1):\n",
        "    data_1_max = np.concatenate((data_1.max(axis=0),data_1.max(axis=1)),axis=0).max(axis=0)\n",
        "    data_1_min = np.concatenate((data_1.min(axis=0),data_1.min(axis=1)),axis=0).min(axis=0)\n",
        "    if (len(np.where((data_1_max - data_1_min) == 0)[0]) > 0):\n",
        "        return data_1\n",
        "    data_1_max_rep = np.tile(data_1_max,(data_1.shape[0],data_1.shape[1],1))\n",
        "    data_1_min_rep = np.tile(data_1_min,(data_1.shape[0],data_1.shape[1],1))\n",
        "    data_1_norm = (data_1 - data_1_min_rep) / (data_1_max_rep - data_1_min_rep)\n",
        "    return  data_1_norm\n",
        "\n",
        "def zero_padding(data, T_MAX):\n",
        "    data_pad = []\n",
        "    for i in range(len(data)):\n",
        "        t = np.array(data[i]).shape[2]\n",
        "        data_pad.append(np.pad(data[i], ((0,0),(0,0),(T_MAX - t,0)), 'constant', constant_values = 0).tolist())\n",
        "    return np.array(data_pad)\n",
        "\n",
        "def onehot_encoding(label, num_class):\n",
        "    label = np.array(label).astype('int32')\n",
        "    label = np.squeeze(label)\n",
        "    # _label = np.eye(num_class)[label-1]     # from label to onehot\n",
        "    _label = np.eye(num_class)[label-2]   #修改点2\n",
        "    return _label\n",
        "\n",
        "def load_data(path_to_data, motion_sel):\n",
        "    global T_MAX\n",
        "    data = []\n",
        "    label = []\n",
        "    for data_root, data_dirs, data_files in os.walk(path_to_data):\n",
        "        for data_file_name in data_files:\n",
        "            file_path = os.path.join(data_root,data_file_name)\n",
        "            try:\n",
        "                data_1 = scio.loadmat(file_path)['velocity_spectrum_ro']\n",
        "                label_1 = int(data_file_name.split('-')[1])\n",
        "                #repetition = int(data_file_name.split('-')[4])\n",
        "                repetition = int(data_file_name.split('-')[2])  #修改点3\n",
        "                # Select Motion\n",
        "                if (label_1 not in motion_sel):\n",
        "                    continue\n",
        "                data_normed_1 = normalize_data(data_1)\n",
        "                if T_MAX < np.array(data_1).shape[2]:\n",
        "                    T_MAX = np.array(data_1).shape[2]\n",
        "            except Exception:\n",
        "                continue\n",
        "            # Save List\n",
        "            data.append(data_normed_1.tolist())\n",
        "            label.append(label_1)\n",
        "                # Zero-padding\n",
        "    data = zero_padding(data, T_MAX)\n",
        "\n",
        "    # Swap axes\n",
        "    data = np.swapaxes(np.swapaxes(data, 1, 3), 2, 3)   # [N,20,20',T_MAX]=>[N,T_MAX,20,20']\n",
        "    data = np.expand_dims(data, axis=-1)    # [N,T_MAX,20,20]=>[N,T_MAX,20,20,1]\n",
        "\n",
        "    # Convert label to ndarray\n",
        "    label = np.array(label)\n",
        "\n",
        "    # data(ndarray): [N,T_MAX,20,20,1], label(ndarray): [N,N_MOTION]\n",
        "    return data, label\n",
        "\n",
        "# 构建符合输入形状为 (None, 20, 15, 15, 1) 和输出形状为 (None, 4) 的  模型：\n",
        "#加Transformer修改点3\n",
        "def transformer_layer(inputs, hidden_units, dropout_rate):\n",
        "    # Self-attention\n",
        "    attention_output = MultiHeadAttention(\n",
        "        num_heads=8, key_dim=hidden_units // 8\n",
        "    )(inputs, inputs)\n",
        "    attention_output = Dropout(dropout_rate)(attention_output)\n",
        "    attention_output = LayerNormalization()(attention_output + inputs)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ffn = Dense(hidden_units, activation=\"relu\")(attention_output)\n",
        "    ffn = Dense(hidden_units)(ffn)\n",
        "    ffn = Dropout(dropout_rate)(ffn)\n",
        "    ffn = LayerNormalization()(ffn)\n",
        "\n",
        "    return ffn\n",
        "\n",
        "#加Transformer修改点4\n",
        "def assemble_model(input_shape, n_class):\n",
        "    model_input = Input(shape=input_shape, dtype='float32', name='name_model_input')    # (@,T_MAX,20,20,1)\n",
        "\n",
        "    # Feature extraction part\n",
        "    x = TimeDistributed(Conv2D(16,kernel_size=(5,5),activation='relu',data_format='channels_last',\\\n",
        "        input_shape=input_shape))(model_input)   # (@,T_MAX,20,20,1)=>(@,T_MAX,16,16,16)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x)    # (@,T_MAX,16,16,16)=>(@,T_MAX,8,8,16)\n",
        "    x = TimeDistributed(Flatten())(x)   # (@,T_MAX,8,8,16)=>(@,T_MAX,8*8*16)\n",
        "    x = TimeDistributed(Dense(64,activation='relu'))(x) # (@,T_MAX,8*8*16)=>(@,T_MAX,64)\n",
        "    x = TimeDistributed(Dropout(f_dropout_ratio))(x)\n",
        "    x = TimeDistributed(Dense(64,activation='relu'))(x) # (@,T_MAX,64)=>(@,T_MAX,64)\n",
        "\n",
        "    # Add transformer layers\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = transformer_layer(x, hidden_units=64, dropout_rate=f_dropout_ratio)  # 修改点1\n",
        "    x = LSTM(n_gru_hidden_units,return_sequences=False)(x)  # (@,T_MAX,64)=>(@,128)\n",
        "    x = Dropout(f_dropout_ratio)(x)\n",
        "    model_output = Dense(n_class, activation='softmax', name='name_model_output')(x)  # (@,128)=>(@,n_class)\n",
        "\n",
        "    # Create the model\n",
        "    # Model compiling\n",
        "    model = Model(inputs=model_input, outputs=model_output)\n",
        "    model.compile(optimizer=keras.optimizers.RMSprop(lr=f_learning_rate),\n",
        "                    loss='mean_squared_error',  # 将损失函数改为均方误差\n",
        "                    metrics=['accuracy']\n",
        "                )\n",
        "    return model\n",
        "\n",
        "model_type = 'FEDRT-LSTM'\n",
        "\n",
        "# 创建结果文件夹\n",
        "result_folder = f'Result_528TRAIN-zhangmengTEST'\n",
        "os.makedirs(result_folder, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "RcrUiRWM2gKB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's BEGIN >>>>\n",
        "\n",
        "# 定义版本\n",
        "today_version = '2024.04.24_v0.1'\n",
        "\n",
        "import time\n",
        "start_time = time.time()  # 记录程序开始时间\n",
        "\n",
        "# 获取可见的 GPU 设备列表\n",
        "visible_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(visible_gpus) > 0:\n",
        "    # 如果有可见的 GPU 设备，设置 TensorFlow 在 GPU 上运行\n",
        "    tf.config.set_visible_devices(visible_gpus, 'GPU')\n",
        "    gpu_config = tf.config.experimental.set_memory_growth(visible_gpus[0], True)\n",
        "    sess = tf.compat.v1.Session(config=gpu_config)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "    print('GPU available')\n",
        "else:\n",
        "    # 如果没有可见的 GPU 设备，设置 TensorFlow 在 CPU 上运行\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "    sess = tf.compat.v1.Session()\n",
        "    print('No GPU available')\n",
        "\n",
        "# 加载训练集数据\n",
        "train_data, train_label = load_data(data_dir_training, ALL_MOTION)\n",
        "print('\\nLoaded dataset of ' + str(train_label.shape[0]) + ' samples, each sized ' + str(train_data[0,:,:].shape) + '\\n')\n",
        "\n",
        "# One-hot encoding for train data\n",
        "train_label = onehot_encoding(train_label, N_MOTION)\n",
        "\n",
        "##############################################################################\n",
        "# Load data\n",
        "# data, label = load_data(data_dir, ALL_MOTION)\n",
        "# print('\\nLoaded dataset of ' + str(label.shape[0]) + ' samples, each sized ' + str(data[0,:,:].shape) + '\\n')\n",
        "\n",
        "# Split train and test\n",
        "# [data_train, data_test, label_train, label_test] = train_test_split(data, label, test_size=fraction_for_test)\n",
        "# print('\\nTrain on ' + str(label_train.shape[0]) + ' samples\\n' +\\\n",
        "    # 'Test on ' + str(label_test.shape[0]) + ' samples\\n')\n",
        "\n",
        "# One-hot encoding for train data\n",
        "# label_train = onehot_encoding(label_train, N_MOTION)\n",
        "\n",
        "# Load or fabricate model\n",
        "if use_existing_model:\n",
        "    model = load_model('model_Transformer_MultiAttention_LSTM_mse_1层Transformer_epoch200_86.61%.h5')\n",
        "    # model = load_model('model_LSTM_91.07_best_trained.h5')\n",
        "    # model = load_model('model_MultiAttention_LSTM_1层Transformer_MSE_epoch200_BS32_lr0.001_86.61%.h5')\n",
        "    # model = load_model('MultiAttention_LSTM_mse_1层Transformer_epoch50_79.46%.h5')\n",
        "    model.summary()\n",
        "else:\n",
        "    model = assemble_model(input_shape=(T_MAX, 15, 15, 1), n_class=N_MOTION) #修改点4\n",
        "    model.summary()\n",
        "\n",
        "class AccuracyLossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.acc = []\n",
        "        self.loss = []\n",
        "        self.val_acc = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.acc.append(logs.get('accuracy'))\n",
        "        self.loss.append(logs.get('loss'))\n",
        "        self.val_acc.append(logs.get('val_accuracy'))\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "\n",
        "history = AccuracyLossHistory()\n",
        "\n",
        "# model.fit({'name_model_input': data_train},{'name_model_output': label_train},\n",
        "model.fit({'name_model_input': train_data},{'name_model_output': train_label},\n",
        "          batch_size=n_batch_size,\n",
        "          epochs=n_epochs,\n",
        "          verbose=1,\n",
        "          # validation_split=0.1,\n",
        "          shuffle=True, callbacks=[history])\n",
        "print('Saving trained model...')\n",
        "#model.save('model_widar3_trained.h5')\n",
        "model.save(f'{result_folder}/{today_version}_FEDRT-LSTM-train-model.h5')  # 改动\n",
        "\n",
        "# Testing...\n",
        "print('Testing...')\n",
        "\n",
        "# 加载测试集数据\n",
        "test_data, test_label = load_data(data_dir_testing, ALL_MOTION)\n",
        "print('\\nLoaded dataset of ' + str(test_label.shape[0]) + ' samples, each sized ' + str(test_data[0,:,:].shape) + '\\n')\n",
        "\n",
        "label_test_pred = model.predict(test_data)\n",
        "label_test_pred = np.argmax(label_test_pred, axis = -1) + 2 #修改点5\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_label, label_test_pred)\n",
        "# print(cm)\n",
        "cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = np.around(cm, decimals=2) # 保留几位小数的意思\n",
        "# print(cm)\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels=range(1, N_MOTION+1)).plot()\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels=range(4, N_MOTION+3)).plot() #2345 lebel-2  4567 4=2+2  7=长度4+3\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels=range(2, N_MOTION+2)).plot() #2345 lebel-2  4567 4=2+2  7=长度4+3\n",
        "plt.show()\n",
        "plt.savefig(f'{result_folder}/{today_version}_Confusion-Matrix.png') # 新增点1 保存混淆矩阵结果2023.09.11\n",
        "\n",
        "# ########################################################\n",
        "# 添加其他指标\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "\n",
        "# label_test_pred是模型的预测结果，label_test是真实的标签\n",
        "classification_result = classification_report(label_test, label_test_pred, digits=4)\n",
        "\n",
        "print(classification_result)\n",
        "\n",
        "# 将分类报告保存到文本文件\n",
        "classification_file = os.path.join(result_folder, 'classification_report.txt')\n",
        "with open(classification_file, 'w') as f:\n",
        "    f.write(classification_result)\n",
        "\n",
        "###############################################################\n",
        "\n",
        "# Accuracy 新增百分号\n",
        "test_accuracy = np.sum(label_test == label_test_pred) / (label_test.shape[0])\n",
        "print(test_accuracy)\n",
        "test_accuracy_percentage = test_accuracy * 100\n",
        "test_accuracy_str = f\"{test_accuracy_percentage:.2f}%\"\n",
        "print(test_accuracy_str)\n",
        "\n",
        "df_accuracy = pd.DataFrame({'Test Accuracy': [test_accuracy]})\n",
        "df_accuracy.to_excel(f'{result_folder}/{test_accuracy_str}_{today_version}.xlsx', index=False) ## 新增点2 保存测试集平均准确率结果2023.09.11\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Epoch': range(1, n_epochs+1),\n",
        "    'Train Accuracy': history.acc,\n",
        "    'Train Loss': history.loss,\n",
        "    'Validation Accuracy': history.val_acc,\n",
        "    'Validation Loss': history.val_loss\n",
        "})\n",
        "\n",
        "# 保存准确率和损失数据到Excel表格中\n",
        "df.to_excel(f'{result_folder}/{today_version}_accuracy_loss.xlsx', index=False) #改动\n",
        "\n",
        "plt.plot(range(1, n_epochs+1), history.acc, label='Train Accuracy')\n",
        "plt.plot(range(1, n_epochs+1), history.loss, label='Train Loss')\n",
        "plt.plot(range(1, n_epochs+1), history.val_acc, label='Validation Accuracy')\n",
        "plt.plot(range(1, n_epochs+1), history.val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.savefig(f'{result_folder}/{today_version}_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 新增 修改文件名 并打印新的文件名\n",
        "new_result_folder = result_folder + f'_{test_accuracy_str}'\n",
        "os.rename(result_folder, new_result_folder)\n",
        "result_folder = new_result_folder\n",
        "\n",
        "# print(\"新的结果文件夹名称为：\", result_folder)\n",
        "\n",
        "end_time = time.time()  # 记录程序结束时间\n",
        "duration = end_time - start_time  # 计算程序运行时间\n",
        "print(\"程序执行时间为：{:.2f}秒\".format(duration))\n",
        "\n",
        "with open(f'{result_folder}/{today_version}_runtime.txt', 'w') as f:\n",
        "    f.write(\"程序执行时间为：{:.2f}秒\".format(duration)) # 新增点3 保存程序执行时间结果2023.09.11\n"
      ],
      "metadata": {
        "id": "Q_ujmBdVPZzU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd080d05-c8e8-4fc7-e6f5-f2c3f2d8f7ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available\n",
            "\n",
            "Loaded dataset of 1120 samples, each sized (20, 15, 15, 1)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " name_model_input (InputLay  [(None, 20, 15, 15, 1)]      0         []                            \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " time_distributed_6 (TimeDi  (None, 20, 11, 11, 16)       416       ['name_model_input[0][0]']    \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " time_distributed_7 (TimeDi  (None, 20, 5, 5, 16)         0         ['time_distributed_6[0][0]']  \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " time_distributed_8 (TimeDi  (None, 20, 400)              0         ['time_distributed_7[0][0]']  \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " time_distributed_9 (TimeDi  (None, 20, 64)               25664     ['time_distributed_8[0][0]']  \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " time_distributed_10 (TimeD  (None, 20, 64)               0         ['time_distributed_9[0][0]']  \n",
            " istributed)                                                                                      \n",
            "                                                                                                  \n",
            " time_distributed_11 (TimeD  (None, 20, 64)               4160      ['time_distributed_10[0][0]'] \n",
            " istributed)                                                                                      \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 20, 64)               16640     ['time_distributed_11[0][0]', \n",
            " ltiHeadAttention)                                                   'time_distributed_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 20, 64)               0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (None, 20, 64)               0         ['dropout_6[0][0]',           \n",
            " OpLambda)                                                           'time_distributed_11[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 20, 64)               128       ['tf.__operators__.add_2[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 20, 64)               4160      ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 20, 64)               4160      ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 20, 64)               0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 20, 64)               128       ['dropout_7[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 32)                   12416     ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 32)                   0         ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " name_model_output (Dense)   (None, 4)                    132       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 68004 (265.64 KB)\n",
            "Trainable params: 68004 (265.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "35/35 [==============================] - 5s 34ms/step - loss: 0.1943 - accuracy: 0.2464\n",
            "Epoch 2/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.1900 - accuracy: 0.2688\n",
            "Epoch 3/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.1878 - accuracy: 0.2875\n",
            "Epoch 4/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1852 - accuracy: 0.3107\n",
            "Epoch 5/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.1827 - accuracy: 0.3241\n",
            "Epoch 6/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1817 - accuracy: 0.3634\n",
            "Epoch 7/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1802 - accuracy: 0.3580\n",
            "Epoch 8/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1778 - accuracy: 0.3830\n",
            "Epoch 9/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.1736 - accuracy: 0.4125\n",
            "Epoch 10/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.1725 - accuracy: 0.4196\n",
            "Epoch 11/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.1676 - accuracy: 0.4518\n",
            "Epoch 12/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1638 - accuracy: 0.4634\n",
            "Epoch 13/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.1588 - accuracy: 0.4964\n",
            "Epoch 14/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.1584 - accuracy: 0.5188\n",
            "Epoch 15/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.1556 - accuracy: 0.5152\n",
            "Epoch 16/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1540 - accuracy: 0.5143\n",
            "Epoch 17/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1520 - accuracy: 0.5339\n",
            "Epoch 18/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1435 - accuracy: 0.5688\n",
            "Epoch 19/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.1444 - accuracy: 0.5607\n",
            "Epoch 20/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1397 - accuracy: 0.5786\n",
            "Epoch 21/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1358 - accuracy: 0.5893\n",
            "Epoch 22/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1283 - accuracy: 0.6286\n",
            "Epoch 23/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1259 - accuracy: 0.6348\n",
            "Epoch 24/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.1252 - accuracy: 0.6455\n",
            "Epoch 25/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.1240 - accuracy: 0.6455\n",
            "Epoch 26/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.1198 - accuracy: 0.6545\n",
            "Epoch 27/200\n",
            "35/35 [==============================] - 1s 36ms/step - loss: 0.1219 - accuracy: 0.6348\n",
            "Epoch 28/200\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 0.1137 - accuracy: 0.6679\n",
            "Epoch 29/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.1067 - accuracy: 0.7125\n",
            "Epoch 30/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.1112 - accuracy: 0.6839\n",
            "Epoch 31/200\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 0.1081 - accuracy: 0.6920\n",
            "Epoch 32/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.1082 - accuracy: 0.7036\n",
            "Epoch 33/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0999 - accuracy: 0.7268\n",
            "Epoch 34/200\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0978 - accuracy: 0.7384\n",
            "Epoch 35/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0988 - accuracy: 0.7277\n",
            "Epoch 36/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0981 - accuracy: 0.7205\n",
            "Epoch 37/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0958 - accuracy: 0.7304\n",
            "Epoch 38/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0947 - accuracy: 0.7312\n",
            "Epoch 39/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0904 - accuracy: 0.7634\n",
            "Epoch 40/200\n",
            "35/35 [==============================] - 1s 35ms/step - loss: 0.0938 - accuracy: 0.7411\n",
            "Epoch 41/200\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 0.0916 - accuracy: 0.7482\n",
            "Epoch 42/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0886 - accuracy: 0.7518\n",
            "Epoch 43/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0903 - accuracy: 0.7527\n",
            "Epoch 44/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0861 - accuracy: 0.7768\n",
            "Epoch 45/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0855 - accuracy: 0.7688\n",
            "Epoch 46/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0788 - accuracy: 0.7937\n",
            "Epoch 47/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0812 - accuracy: 0.7777\n",
            "Epoch 48/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0794 - accuracy: 0.7786\n",
            "Epoch 49/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0797 - accuracy: 0.7884\n",
            "Epoch 50/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0775 - accuracy: 0.7902\n",
            "Epoch 51/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0761 - accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0776 - accuracy: 0.8009\n",
            "Epoch 53/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0729 - accuracy: 0.8089\n",
            "Epoch 54/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0729 - accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0712 - accuracy: 0.8089\n",
            "Epoch 56/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0698 - accuracy: 0.8116\n",
            "Epoch 57/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0703 - accuracy: 0.8205\n",
            "Epoch 58/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0680 - accuracy: 0.8152\n",
            "Epoch 59/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0673 - accuracy: 0.8161\n",
            "Epoch 60/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0663 - accuracy: 0.8250\n",
            "Epoch 61/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0717 - accuracy: 0.8125\n",
            "Epoch 62/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0655 - accuracy: 0.8295\n",
            "Epoch 63/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0622 - accuracy: 0.8348\n",
            "Epoch 64/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0626 - accuracy: 0.8366\n",
            "Epoch 65/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0657 - accuracy: 0.8250\n",
            "Epoch 66/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0614 - accuracy: 0.8366\n",
            "Epoch 67/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0598 - accuracy: 0.8357\n",
            "Epoch 68/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0625 - accuracy: 0.8384\n",
            "Epoch 69/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0605 - accuracy: 0.8402\n",
            "Epoch 70/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0560 - accuracy: 0.8509\n",
            "Epoch 71/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0549 - accuracy: 0.8580\n",
            "Epoch 72/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0536 - accuracy: 0.8598\n",
            "Epoch 73/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0537 - accuracy: 0.8607\n",
            "Epoch 74/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0537 - accuracy: 0.8580\n",
            "Epoch 75/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0541 - accuracy: 0.8625\n",
            "Epoch 76/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0568 - accuracy: 0.8464\n",
            "Epoch 77/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0540 - accuracy: 0.8670\n",
            "Epoch 78/200\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 0.0502 - accuracy: 0.8652\n",
            "Epoch 79/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0500 - accuracy: 0.8634\n",
            "Epoch 80/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0533 - accuracy: 0.8562\n",
            "Epoch 81/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0488 - accuracy: 0.8741\n",
            "Epoch 82/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0536 - accuracy: 0.8661\n",
            "Epoch 83/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0520 - accuracy: 0.8652\n",
            "Epoch 84/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0485 - accuracy: 0.8777\n",
            "Epoch 85/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0522 - accuracy: 0.8634\n",
            "Epoch 86/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0514 - accuracy: 0.8652\n",
            "Epoch 87/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0476 - accuracy: 0.8777\n",
            "Epoch 88/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0472 - accuracy: 0.8804\n",
            "Epoch 89/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0432 - accuracy: 0.8884\n",
            "Epoch 90/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0453 - accuracy: 0.8857\n",
            "Epoch 91/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0438 - accuracy: 0.8991\n",
            "Epoch 92/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0451 - accuracy: 0.8866\n",
            "Epoch 93/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0430 - accuracy: 0.8929\n",
            "Epoch 94/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0460 - accuracy: 0.8848\n",
            "Epoch 95/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0414 - accuracy: 0.8964\n",
            "Epoch 96/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0384 - accuracy: 0.9018\n",
            "Epoch 97/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0426 - accuracy: 0.8946\n",
            "Epoch 98/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0412 - accuracy: 0.8964\n",
            "Epoch 99/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0418 - accuracy: 0.8929\n",
            "Epoch 100/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0464 - accuracy: 0.8786\n",
            "Epoch 101/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0416 - accuracy: 0.8982\n",
            "Epoch 102/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0430 - accuracy: 0.8911\n",
            "Epoch 103/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0382 - accuracy: 0.9018\n",
            "Epoch 104/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0404 - accuracy: 0.8982\n",
            "Epoch 105/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0357 - accuracy: 0.9080\n",
            "Epoch 106/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0416 - accuracy: 0.8911\n",
            "Epoch 107/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0421 - accuracy: 0.8946\n",
            "Epoch 108/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0396 - accuracy: 0.9018\n",
            "Epoch 109/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0372 - accuracy: 0.9009\n",
            "Epoch 110/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0359 - accuracy: 0.9071\n",
            "Epoch 111/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0395 - accuracy: 0.8982\n",
            "Epoch 112/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0364 - accuracy: 0.9080\n",
            "Epoch 113/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0372 - accuracy: 0.9071\n",
            "Epoch 114/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0371 - accuracy: 0.9036\n",
            "Epoch 115/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0385 - accuracy: 0.8973\n",
            "Epoch 116/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0331 - accuracy: 0.9152\n",
            "Epoch 117/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0377 - accuracy: 0.9018\n",
            "Epoch 118/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0376 - accuracy: 0.9000\n",
            "Epoch 119/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0340 - accuracy: 0.9098\n",
            "Epoch 120/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0357 - accuracy: 0.9125\n",
            "Epoch 121/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0346 - accuracy: 0.9107\n",
            "Epoch 122/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0380 - accuracy: 0.9062\n",
            "Epoch 123/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0365 - accuracy: 0.9107\n",
            "Epoch 124/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0339 - accuracy: 0.9098\n",
            "Epoch 125/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0282 - accuracy: 0.9312\n",
            "Epoch 126/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0345 - accuracy: 0.9143\n",
            "Epoch 127/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0303 - accuracy: 0.9321\n",
            "Epoch 128/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0348 - accuracy: 0.9143\n",
            "Epoch 129/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0291 - accuracy: 0.9250\n",
            "Epoch 130/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0323 - accuracy: 0.9232\n",
            "Epoch 131/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0313 - accuracy: 0.9286\n",
            "Epoch 132/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0327 - accuracy: 0.9187\n",
            "Epoch 133/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0353 - accuracy: 0.9116\n",
            "Epoch 134/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0313 - accuracy: 0.9196\n",
            "Epoch 135/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0312 - accuracy: 0.9152\n",
            "Epoch 136/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0297 - accuracy: 0.9259\n",
            "Epoch 137/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0291 - accuracy: 0.9241\n",
            "Epoch 138/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0308 - accuracy: 0.9277\n",
            "Epoch 139/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0286 - accuracy: 0.9312\n",
            "Epoch 140/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0271 - accuracy: 0.9339\n",
            "Epoch 141/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0292 - accuracy: 0.9312\n",
            "Epoch 142/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0302 - accuracy: 0.9250\n",
            "Epoch 143/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0280 - accuracy: 0.9330\n",
            "Epoch 144/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0336 - accuracy: 0.9152\n",
            "Epoch 145/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0257 - accuracy: 0.9321\n",
            "Epoch 146/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0292 - accuracy: 0.9259\n",
            "Epoch 147/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0297 - accuracy: 0.9232\n",
            "Epoch 148/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0253 - accuracy: 0.9411\n",
            "Epoch 149/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0278 - accuracy: 0.9268\n",
            "Epoch 150/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0253 - accuracy: 0.9357\n",
            "Epoch 151/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0292 - accuracy: 0.9304\n",
            "Epoch 152/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0276 - accuracy: 0.9268\n",
            "Epoch 153/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0235 - accuracy: 0.9411\n",
            "Epoch 154/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0319 - accuracy: 0.9205\n",
            "Epoch 155/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0282 - accuracy: 0.9321\n",
            "Epoch 156/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0271 - accuracy: 0.9330\n",
            "Epoch 157/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0237 - accuracy: 0.9455\n",
            "Epoch 158/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0248 - accuracy: 0.9420\n",
            "Epoch 159/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0295 - accuracy: 0.9250\n",
            "Epoch 160/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0264 - accuracy: 0.9384\n",
            "Epoch 161/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0259 - accuracy: 0.9366\n",
            "Epoch 162/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0234 - accuracy: 0.9473\n",
            "Epoch 163/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0283 - accuracy: 0.9304\n",
            "Epoch 164/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0236 - accuracy: 0.9429\n",
            "Epoch 165/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0206 - accuracy: 0.9491\n",
            "Epoch 166/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0213 - accuracy: 0.9500\n",
            "Epoch 167/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0270 - accuracy: 0.9348\n",
            "Epoch 168/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0222 - accuracy: 0.9455\n",
            "Epoch 169/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0259 - accuracy: 0.9393\n",
            "Epoch 170/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0253 - accuracy: 0.9384\n",
            "Epoch 171/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0247 - accuracy: 0.9420\n",
            "Epoch 172/200\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0257 - accuracy: 0.9393\n",
            "Epoch 173/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0271 - accuracy: 0.9348\n",
            "Epoch 174/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0272 - accuracy: 0.9366\n",
            "Epoch 175/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0244 - accuracy: 0.9402\n",
            "Epoch 176/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0247 - accuracy: 0.9348\n",
            "Epoch 177/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0240 - accuracy: 0.9393\n",
            "Epoch 178/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0245 - accuracy: 0.9393\n",
            "Epoch 179/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0238 - accuracy: 0.9384\n",
            "Epoch 180/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0254 - accuracy: 0.9366\n",
            "Epoch 181/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0282 - accuracy: 0.9277\n",
            "Epoch 182/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0204 - accuracy: 0.9491\n",
            "Epoch 183/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0234 - accuracy: 0.9446\n",
            "Epoch 184/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0243 - accuracy: 0.9384\n",
            "Epoch 185/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0198 - accuracy: 0.9509\n",
            "Epoch 186/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0211 - accuracy: 0.9473\n",
            "Epoch 187/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0213 - accuracy: 0.9500\n",
            "Epoch 188/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0211 - accuracy: 0.9527\n",
            "Epoch 189/200\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 0.0168 - accuracy: 0.9589\n",
            "Epoch 190/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0247 - accuracy: 0.9357\n",
            "Epoch 191/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0189 - accuracy: 0.9545\n",
            "Epoch 192/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0246 - accuracy: 0.9446\n",
            "Epoch 193/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0249 - accuracy: 0.9402\n",
            "Epoch 194/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0210 - accuracy: 0.9473\n",
            "Epoch 195/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0226 - accuracy: 0.9438\n",
            "Epoch 196/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9571\n",
            "Epoch 197/200\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 0.0203 - accuracy: 0.9500\n",
            "Epoch 198/200\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 0.0246 - accuracy: 0.9420\n",
            "Epoch 199/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0196 - accuracy: 0.9545\n",
            "Epoch 200/200\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 0.0215 - accuracy: 0.9500\n",
            "Saving trained model...\n",
            "Testing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded dataset of 84 samples, each sized (20, 15, 15, 1)\n",
            "\n",
            "3/3 [==============================] - 1s 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-fec2b6bd801e>:94: RuntimeWarning: invalid value encountered in divide\n",
            "  cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (3).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fec2b6bd801e>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# print(cm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mcm_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_MOTION\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mcm_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_MOTION\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2345 lebel-2  4567 4=2+2  7=长度4+3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mcm_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_MOTION\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2345 lebel-2  4567 4=2+2  7=长度4+3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         ax.set(\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;31m# Artist._update_set_signature_and_docstring() at the end of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;31m# module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlack\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprenormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaintain\u001b[0m \u001b[0mbackcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{cls.__name__}.set() got an unexpected keyword argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \"{prop_name!r}\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                         raise AttributeError(\n\u001b[1;32m   1198\u001b[0m                             errfmt.format(cls=type(self), prop_name=k))\n\u001b[0;32m-> 1199\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 f\"for the old name will be dropped %(removal)s.\")\n\u001b[1;32m    296\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# wrapper() must keep the same documented signature as func(): if we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1970\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (3)."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_INGrZ9z6iA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}